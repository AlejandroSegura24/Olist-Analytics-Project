# üìÇ Database Setup & Data Ingestion

Este m√≥dulo constituye el n√∫cleo de datos del proyecto. Aqu√≠ se gestiona desde la creaci√≥n de la infraestructura f√≠sica y la ingesta de datos, hasta la validaci√≥n de calidad y la creaci√≥n de capas anal√≠ticas.

## 1) Contexto y Prop√≥sito
El objetivo de este script es transformar archivos planos (CSV) en una base de datos relacional robusta. En el contexto de Olist, esto es cr√≠tico porque:
* **Normalizaci√≥n:** Permite cruzar la informaci√≥n de clientes, vendedores y productos sin redundancias.
* **Trazabilidad:** Establece las reglas para entender el ciclo de vida de una orden, desde la compra hasta la rese√±a del cliente.

## 2) Fase 1: Creaci√≥n e Ingesta (01_schema_and_load.sql) üèóÔ∏è

En esta etapa se define la estructura t√©cnica del proyecto. Se priorizaron decisiones que garantizan la precisi√≥n y la escalabilidad:

* **Precisi√≥n Financiera:** Se utiliza el tipo de dato `DECIMAL(10,2)` para los campos de precio, flete y pagos. A diferencia del tipo `FLOAT`, este evita errores de redondeo acumulativos en c√°lculos de Revenue.
* **Trazabilidad Temporal:** Uso de `TIMESTAMP` para todos los hitos log√≠sticos, permitiendo c√°lculos precisos de intervalos (SLA).
* **Eficiencia de Ingesta:** Se emple√≥ el comando `COPY` de PostgreSQL para una carga masiva y eficiente de los archivos CSV originales en formato UTF-8.

### 1.1 Diagrama de Entidad-Relaci√≥n (ERD) üó∫Ô∏è

A continuaci√≥n se presenta la arquitectura l√≥gica de la base de datos de Olist, destacando las relaciones entre las 9 tablas principales:

![ERD Olist High Resolution](../assets/erd_diagram.png)
*Figura 1: Esquema relacional que muestra la integridad referencial y las claves compuestas.*

### 1.2 Diccionario de Datos Completo üìñ

| Tabla | Tipo | Descripci√≥n |
| :--- | :--- | :--- |
| `customers` | Dimensi√≥n | Datos de clientes y ubicaci√≥n. |
| `products` | Dimensi√≥n | Cat√°logo con dimensiones f√≠sicas de productos. |
| `sellers` | Dimensi√≥n | Informaci√≥n de los vendedores del marketplace. |
| `name_category`| Referencia | Traducci√≥n de categor√≠as (Portugu√©s -> Ingl√©s). |
| `geolocation` | Referencia | Coordenadas geogr√°ficas por c√≥digo postal. |
| `orders` | Hechos | Cabecera del pedido (Status y Timestamps). |
| `order_items` | Hechos | Detalle de productos, precios y fletes por pedido. |
| `order_payments`| Hechos | Transacciones, m√©todos de pago y cuotas. |
| `reviews` | Hechos | Calificaciones y comentarios de los usuarios. |

### 1.3 Hallazgos Clave üí°

* **Granularidad de Clientes:** La distinci√≥n entre `customer_id` y `customer_unique_id` permite rastrear el comportamiento recurrente del usuario a trav√©s de m√∫ltiples √≥rdenes.
* **Consistencia de Datos:** Durante la ingesta se valid√≥ la codificaci√≥n `UTF8` para preservar los caracteres especiales del portugu√©s brasile√±o en nombres de ciudades y categor√≠as.

## 3) Fase 2: Pre-procesamiento y Calidad de Datos (02_pre_processing_analysis.sql) üîç

Antes de generar m√©tricas de negocio, se ejecut√≥ un an√°lisis de integridad exhaustivo. Este paso es fundamental para asegurar que las visualizaciones en Power BI no contengan sesgos por datos ruidosos o reglas de negocio no identificadas.

### 2.1 Auditor√≠a de Flujo Log√≠stico (Nulos en Fechas) üß™

Tras auditar los estados de las √≥rdenes frente a sus fechas de cumplimiento, se obtuvieron los siguientes resultados que validan la consistencia del dataset:

| Estado del Pedido | Total Pedidos | Fechas Nulas | Conclusi√≥n de Calidad |
| :--- | :--- | :--- | :--- |
| **delivered** | 96,478 | 8 | **Alta Integridad:** Solo 0.008% de error en registro de entrega. |
| **shipped** | 1,107 | 1,107 | **Consistencia L√≥gica:** Pedidos en tr√°nsito correctamente sin fecha final. |
| **canceled** | 625 | 619 | **Excepci√≥n:** 6 pedidos cancelados reportan entrega (posible retorno). |

### 2.2 Resoluci√≥n de Conflictos Geogr√°ficos (Duplicados) üìç

Se valid√≥ la cardinalidad de la tabla `geolocation` para prevenir errores de duplicidad en reportes espaciales.
* **Hallazgo:** El campo `geolocation_zip_code_prefix` presenta m√∫ltiples registros de latitud/longitud por cada c√≥digo postal.
* **Impacto en el Modelo:** Esta duplicidad impide el uso del c√≥digo postal como Primary Key. Se documenta que cualquier JOIN con esta tabla debe realizarse tras un proceso de agregaci√≥n (promedio de coordenadas) para evitar el efecto de "explosi√≥n de filas" (*fan-out effect*).

### 2.3 Auditor√≠a de Integridad Financiera e Intereses üí∞

Se realiz√≥ una validaci√≥n cruzada entre el monto esperado (Precio + Flete) y el monto efectivamente pagado en la pasarela de pagos, dividida en dos etapas:

* **Fase A (Identificaci√≥n de Diferencias):** Se detectaron discrepancias donde el pago real superaba el valor del carrito. Se estableci√≥ un umbral de tolerancia de 0.1 para ignorar errores m√≠nimos por redondeo.
* **Fase B (Validaci√≥n de Hip√≥tesis):** Se cruzaron las diferencias con el n√∫mero de cuotas (`payment_installments`). 
* **Conclusi√≥n de Negocio:** Se confirm√≥ que el dataset de Olist incluye **costos de financiamiento**. El excedente de pago corresponde a intereses que crecen proporcionalmente al n√∫mero de cuotas elegidas por el cliente.

![Resultados de Auditor√≠a Financiera](../assets/financial_audit_results.png) 

*Figura 2: Detalle de pedidos con intereses por cuotas, confirmando el costo de financiamiento.*

| M√©trica Analizada | Hallazgo T√©cnico | Implicaci√≥n de Negocio |
| :--- | :--- | :--- |
| **Diferencia de Montos** | `actual_payment > expected_total` | Identificaci√≥n de ingresos por financiamiento vs. venta. |
| **Costo por Cuotas** | `interest_per_installment` > 0 | Validaci√≥n de la l√≥gica de intereses del marketplace. |
| **Umbral de Tolerancia** | 0.1 (BRL) | Eliminaci√≥n de ruido por precisi√≥n decimal en PostgreSQL. |

> **üí° Insight de Portafolio:** Esta auditor√≠a demuestra que el modelo no presenta errores de duplicidad financiera, sino que refleja fielmente la realidad del cr√©dito al consumo en el mercado brasile√±o.

## 4) Gu√≠a de Ejecuci√≥n ‚öôÔ∏è
1. **Preparaci√≥n:** Crear la base de datos `olist_analytics` y asegurar la conexi√≥n.
2. **Infraestructura e Ingesta:** Ejecutar `01_schema_and_load.sql`.

   > **Nota:** Actualizar las rutas del comando `COPY` a la ubicaci√≥n local de tus archivos CSV.

3. **Validaci√≥n de Calidad:** Ejecutar `02_pre_processing_analysis.sql` para verificar la integridad de la carga y auditar nulos.
4. **Capa Anal√≠tica (Pr√≥ximamente):** Ejecutar `03_views.sql` para generar las tablas finales de Power BI.

